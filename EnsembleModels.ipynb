{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6835ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import strptime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"bank-full.csv\", sep = \";\")\n",
    "\n",
    "# change month to numeric\n",
    "data['month'] = [strptime(str(x), '%b').tm_mon for x in data['month']]\n",
    "# change all object data type to categorical\n",
    "list_str_obj_cols = data.columns[data.dtypes == \"object\"].tolist()\n",
    "for str_obj_col in list_str_obj_cols:\n",
    "    data[str_obj_col] = data[str_obj_col].astype(\"category\")\n",
    "\n",
    "# encode all categorical data\n",
    "df_encoded = pd.get_dummies(data, columns=['job', 'marital', 'education', 'default',\n",
    "                                           'housing', 'loan', 'contact', 'poutcome'], )\n",
    "\n",
    "# standardize all numeric data\n",
    "data_numeric = data[[\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"month\"]]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "df_scaled = std_scaler.fit_transform(data_numeric.to_numpy())\n",
    "df_scaled = pd.DataFrame(df_scaled,\n",
    "                         columns=[\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"month\"])\n",
    "\n",
    "# combine both datasets\n",
    "df_encoded.update(df_scaled)\n",
    "\n",
    "# change class label to 0 and 1\n",
    "df_encoded.y = pd.Categorical(df_encoded.y).codes\n",
    "newdata = df_encoded\n",
    "\n",
    "X = newdata.drop([\"y\"], axis=1)\n",
    "y = newdata[\"y\"]\n",
    "\n",
    "#used for parameter tuning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ddd9db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Scores: [0.40976983875814915, 0.3959852559899423, 0.4011848992019024, 0.41621544752997264, 0.4016352213461504]\n",
      "Accuracy Scores: [0.8995908437465443, 0.9000221190002212, 0.9037823490378235, 0.9021234240212342, 0.900464499004645]\n"
     ]
    }
   ],
   "source": [
    "# Define individual models with best parameters\n",
    "rf = RandomForestClassifier(max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=100, random_state=0)\n",
    "logreg = LogisticRegression(C=1, penalty='l2', solver='liblinear', random_state=0)\n",
    "nn = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=500,\n",
    "                   random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5, random_state=0)\n",
    "\n",
    "# Create an ensemble of the models using a majority class voting strategy\n",
    "ensemble_model = VotingClassifier(estimators=[('rf', rf), ('logreg', logreg), ('nn', nn), ('dt', dt)], voting='hard')\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "mcc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    ensemble_model.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = ensemble_model.predict(X_val_fold)\n",
    "\n",
    "    mcc = matthews_corrcoef(y_val_fold, y_pred)\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
    "\n",
    "    mcc_scores.append(mcc)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "print(\"MCC Scores:\", mcc_scores)\n",
    "print(\"Accuracy Scores:\", accuracy_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f03634",
   "metadata": {},
   "source": [
    "# 加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde29ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Ensemble MCC: 0.4448151709012132\n",
      "Weighted Ensemble Accuracy: 0.8991485126617274\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Calculate the weights based on MCC scores\n",
    "mcc_values = {\n",
    "    'logreg': 0.43491332157004836,\n",
    "    'rf': 0.5147329105011038,\n",
    "    'nn': 0.4531938207274481,\n",
    "    'dt': 0.4505434003255415\n",
    "}\n",
    "\n",
    "total_mcc = sum(mcc_values.values())\n",
    "weights = {model: mcc/total_mcc for model, mcc in mcc_values.items()}\n",
    "\n",
    "# Define individual models with updated parameters\n",
    "rf = RandomForestClassifier(max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=200, random_state=0)\n",
    "logreg = LogisticRegression(C=1, penalty='l2', solver='liblinear', random_state=0)\n",
    "nn = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=500, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5, random_state=0)\n",
    "\n",
    "# Create a weighted ensemble of the models\n",
    "ensemble_weighted_model = VotingClassifier(estimators=[('rf', rf), ('logreg', logreg), ('nn', nn), ('dt', dt)], \n",
    "                                          voting='soft', weights=[weights['rf'], weights['logreg'], weights['nn'], weights['dt']])\n",
    "\n",
    "# Fit the ensemble model\n",
    "ensemble_weighted_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on test set\n",
    "y_pred = ensemble_weighted_model.predict(X_test)\n",
    "\n",
    "mcc_weighted = matthews_corrcoef(y_test, y_pred)\n",
    "accuracy_weighted = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Weighted Ensemble MCC:\", mcc_weighted)\n",
    "print(\"Weighted Ensemble Accuracy:\", accuracy_weighted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f708e0",
   "metadata": {},
   "source": [
    "# 5CV Neural Network + Decision Tree + Logistic Regression + Random Forest Soft Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f30f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Ensemble MCC: [0.46634579584638075, 0.4501952289260701, 0.4539465434753073, 0.47410171172875626, 0.47053221957267233]\n",
      "Weighted Ensemble Accuracy: [0.900807254229791, 0.9020128290201282, 0.9057730590577306, 0.9046671090466711, 0.9044459190444591]\n",
      "Mean MCC for Weighted Ensemble: 0.4630242999098373\n",
      "Mean Accuracy for Weighted Ensemble: 0.903541234079756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Calculate the weights based on MCC scores\n",
    "mcc_values = {\n",
    "    'logreg': 0.43491332157004836,\n",
    "    'rf': 0.5147329105011038,\n",
    "    'nn': 0.4531938207274481,\n",
    "    'dt': 0.4505434003255415\n",
    "}\n",
    "\n",
    "total_mcc = sum(mcc_values.values())\n",
    "weights = {model: mcc/total_mcc for model, mcc in mcc_values.items()}\n",
    "\n",
    "# Define individual models with best parameters\n",
    "rf = RandomForestClassifier(max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=200, random_state=0)\n",
    "logreg = LogisticRegression(C=1, penalty='l2', solver='liblinear', random_state=0)\n",
    "nn = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=500, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5, random_state=0)\n",
    "\n",
    "# Create a weighted ensemble of the models\n",
    "ensemble_weighted_model = VotingClassifier(estimators=[('rf', rf), ('logreg', logreg), ('nn', nn), ('dt', dt)], \n",
    "                                          voting='soft', weights=[weights['rf'], weights['logreg'], weights['nn'], weights['dt']])\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "mcc_scores_weighted = []\n",
    "accuracy_scores_weighted = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Fit the ensemble model on the training fold\n",
    "    ensemble_weighted_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = ensemble_weighted_model.predict(X_val_fold)\n",
    "    \n",
    "    # Compute MCC and accuracy for the current fold\n",
    "    mcc_fold = matthews_corrcoef(y_val_fold, y_pred_fold)\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    mcc_scores_weighted.append(mcc_fold)\n",
    "    accuracy_scores_weighted.append(accuracy_fold)\n",
    "\n",
    "# Compute mean MCC and accuracy over all folds\n",
    "mean_mcc_weighted = sum(mcc_scores_weighted) / len(mcc_scores_weighted)\n",
    "mean_accuracy_weighted = sum(accuracy_scores_weighted) / len(accuracy_scores_weighted)\n",
    "\n",
    "print(\"Weighted Ensemble MCC:\", mcc_scores_weighted)\n",
    "print(\"Weighted Ensemble Accuracy:\", accuracy_scores_weighted)\n",
    "print(\"Mean MCC for Weighted Ensemble:\", mean_mcc_weighted)\n",
    "print(\"Mean Accuracy for Weighted Ensemble:\", mean_accuracy_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1221f",
   "metadata": {},
   "source": [
    "# 5CV Neural Network + Decision Tree + Logistic Regression + Random Forest Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7606bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Ensemble MCC: [0.44129601011216607, 0.43790521259678256, 0.43722909579898145, 0.4611350725988718, 0.4493776563247105]\n",
      "Weighted Ensemble Accuracy: [0.900364923144974, 0.9017916390179164, 0.9046671090466711, 0.9056624640566246, 0.9038929440389294]\n",
      "Mean MCC for Weighted Ensemble: 0.4453886094863025\n",
      "Mean Accuracy for Weighted Ensemble: 0.9032758158610232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Calculate the weights based on MCC scores\n",
    "mcc_values = {\n",
    "    'logreg': 0.43491332157004836,\n",
    "    'rf': 0.5147329105011038,\n",
    "    'nn': 0.4531938207274481,\n",
    "    'dt': 0.4505434003255415\n",
    "}\n",
    "\n",
    "total_mcc = sum(mcc_values.values())\n",
    "weights = {model: mcc/total_mcc for model, mcc in mcc_values.items()}\n",
    "\n",
    "# Define individual models with best parameters\n",
    "rf = RandomForestClassifier(max_depth=60, min_samples_leaf=1, min_samples_split=2, n_estimators=200, random_state=0)\n",
    "logreg = LogisticRegression(C=1, penalty='l2', solver='liblinear', random_state=0)\n",
    "nn = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=500, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5, random_state=0)\n",
    "\n",
    "# Create a weighted ensemble of the models\n",
    "ensemble_weighted_model = VotingClassifier(estimators=[('rf', rf), ('logreg', logreg), ('nn', nn), ('dt', dt)], \n",
    "                                          voting='hard', weights=[weights['rf'], weights['logreg'], weights['nn'], weights['dt']])\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "mcc_scores_weighted = []\n",
    "accuracy_scores_weighted = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Fit the ensemble model on the training fold\n",
    "    ensemble_weighted_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = ensemble_weighted_model.predict(X_val_fold)\n",
    "    \n",
    "    # Compute MCC and accuracy for the current fold\n",
    "    mcc_fold = matthews_corrcoef(y_val_fold, y_pred_fold)\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    mcc_scores_weighted.append(mcc_fold)\n",
    "    accuracy_scores_weighted.append(accuracy_fold)\n",
    "\n",
    "# Compute mean MCC and accuracy over all folds\n",
    "mean_mcc_weighted = sum(mcc_scores_weighted) / len(mcc_scores_weighted)\n",
    "mean_accuracy_weighted = sum(accuracy_scores_weighted) / len(accuracy_scores_weighted)\n",
    "\n",
    "print(\"Weighted Ensemble MCC:\", mcc_scores_weighted)\n",
    "print(\"Weighted Ensemble Accuracy:\", accuracy_scores_weighted)\n",
    "print(\"Mean MCC for Weighted Ensemble:\", mean_mcc_weighted)\n",
    "print(\"Mean Accuracy for Weighted Ensemble:\", mean_accuracy_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bd9bd",
   "metadata": {},
   "source": [
    "# 5CV Neural Network + Decision Tree + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e2a81ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Ensemble MCC: [0.4631143936218434, 0.4530689130929212, 0.4552452624433544, 0.4747581723397219, 0.4731540300055983]\n",
      "Weighted Ensemble Accuracy: [0.8983744332632976, 0.9017916390179164, 0.9051094890510949, 0.9037823490378235, 0.9034505640345056]\n",
      "Mean MCC for Weighted Ensemble: 0.46386815430068784\n",
      "Mean Accuracy for Weighted Ensemble: 0.9025016948809277\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Calculate the weights based on MCC scores\n",
    "mcc_values = {\n",
    "    'logreg': 0.43491332157004836,\n",
    "    'nn': 0.4531938207274481,\n",
    "    'dt': 0.4505434003255415\n",
    "}\n",
    "\n",
    "total_mcc = sum(mcc_values.values())\n",
    "weights = {model: mcc/total_mcc for model, mcc in mcc_values.items()}\n",
    "\n",
    "# Define individual models with best parameters\n",
    "logreg = LogisticRegression(C=1, penalty='l2', solver='liblinear', random_state=0)\n",
    "nn = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=500, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5, random_state=0)\n",
    "\n",
    "# Create a weighted ensemble of the models\n",
    "ensemble_weighted_model = VotingClassifier(estimators=[('logreg', logreg), ('nn', nn), ('dt', dt)], \n",
    "                                          voting='soft', weights=[weights['logreg'], weights['nn'], weights['dt']])\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "mcc_scores_weighted = []\n",
    "accuracy_scores_weighted = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Fit the ensemble model on the training fold\n",
    "    ensemble_weighted_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = ensemble_weighted_model.predict(X_val_fold)\n",
    "    \n",
    "    # Compute MCC and accuracy for the current fold\n",
    "    mcc_fold = matthews_corrcoef(y_val_fold, y_pred_fold)\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    mcc_scores_weighted.append(mcc_fold)\n",
    "    accuracy_scores_weighted.append(accuracy_fold)\n",
    "\n",
    "# Compute mean MCC and accuracy over all folds\n",
    "mean_mcc_weighted = sum(mcc_scores_weighted) / len(mcc_scores_weighted)\n",
    "mean_accuracy_weighted = sum(accuracy_scores_weighted) / len(accuracy_scores_weighted)\n",
    "\n",
    "print(\"Weighted Ensemble MCC:\", mcc_scores_weighted)\n",
    "print(\"Weighted Ensemble Accuracy:\", accuracy_scores_weighted)\n",
    "print(\"Mean MCC for Weighted Ensemble:\", mean_mcc_weighted)\n",
    "print(\"Mean Accuracy for Weighted Ensemble:\", mean_accuracy_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3ae62f",
   "metadata": {},
   "source": [
    "# 5CV Neural Network + Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5b1b994",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jiaqi\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Ensemble MCC: [0.4567033901198766, 0.45217076570372233, 0.46374782622112637, 0.4788808183358292, 0.4780032078726325]\n",
      "Weighted Ensemble Accuracy: [0.8896383943381622, 0.8963724839637248, 0.9015704490157045, 0.8989161689891617, 0.898363193983632]\n",
      "Mean MCC for Weighted Ensemble: 0.46590120165063736\n",
      "Mean Accuracy for Weighted Ensemble: 0.8969721380580771\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Calculate the weights based on MCC scores\n",
    "mcc_values = {\n",
    "    'nn': 0.4531938207274481,\n",
    "    'dt': 0.4505434003255415\n",
    "}\n",
    "\n",
    "total_mcc = sum(mcc_values.values())\n",
    "weights = {model: mcc/total_mcc for model, mcc in mcc_values.items()}\n",
    "\n",
    "# Define individual models with best parameters\n",
    "logreg = LogisticRegression(C=1, penalty='l2', solver='liblinear', random_state=0)\n",
    "nn = MLPClassifier(activation='relu', alpha=0.0001, hidden_layer_sizes=(50, 50), learning_rate_init=0.001, max_iter=500, random_state=0)\n",
    "dt = DecisionTreeClassifier(max_depth=20, min_samples_leaf=4, min_samples_split=5, random_state=0)\n",
    "\n",
    "# Create a weighted ensemble of the models\n",
    "ensemble_weighted_model = VotingClassifier(estimators=[('nn', nn), ('dt', dt)], voting='soft', weights=[weights['nn'], weights['dt']])\n",
    "\n",
    "\n",
    "# Define 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "mcc_scores_weighted = []\n",
    "accuracy_scores_weighted = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # Fit the ensemble model on the training fold\n",
    "    ensemble_weighted_model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Predict on the validation fold\n",
    "    y_pred_fold = ensemble_weighted_model.predict(X_val_fold)\n",
    "    \n",
    "    # Compute MCC and accuracy for the current fold\n",
    "    mcc_fold = matthews_corrcoef(y_val_fold, y_pred_fold)\n",
    "    accuracy_fold = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    \n",
    "    mcc_scores_weighted.append(mcc_fold)\n",
    "    accuracy_scores_weighted.append(accuracy_fold)\n",
    "\n",
    "# Compute mean MCC and accuracy over all folds\n",
    "mean_mcc_weighted = sum(mcc_scores_weighted) / len(mcc_scores_weighted)\n",
    "mean_accuracy_weighted = sum(accuracy_scores_weighted) / len(accuracy_scores_weighted)\n",
    "\n",
    "print(\"Weighted Ensemble MCC:\", mcc_scores_weighted)\n",
    "print(\"Weighted Ensemble Accuracy:\", accuracy_scores_weighted)\n",
    "print(\"Mean MCC for Weighted Ensemble:\", mean_mcc_weighted)\n",
    "print(\"Mean Accuracy for Weighted Ensemble:\", mean_accuracy_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a7ef60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
