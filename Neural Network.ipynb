{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf595b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import strptime\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5e1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/ZHANG FANYUE/Desktop/NTU/Data Mining/Project/bank-full.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dfc651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45211 entries, 0 to 45210\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        45211 non-null  int64 \n",
      " 1   job        45211 non-null  object\n",
      " 2   marital    45211 non-null  object\n",
      " 3   education  45211 non-null  object\n",
      " 4   default    45211 non-null  object\n",
      " 5   balance    45211 non-null  int64 \n",
      " 6   housing    45211 non-null  object\n",
      " 7   loan       45211 non-null  object\n",
      " 8   contact    45211 non-null  object\n",
      " 9   day        45211 non-null  int64 \n",
      " 10  month      45211 non-null  object\n",
      " 11  duration   45211 non-null  int64 \n",
      " 12  campaign   45211 non-null  int64 \n",
      " 13  pdays      45211 non-null  int64 \n",
      " 14  previous   45211 non-null  int64 \n",
      " 15  poutcome   45211 non-null  object\n",
      " 16  y          45211 non-null  object\n",
      "dtypes: int64(7), object(10)\n",
      "memory usage: 5.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a9a08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change month to numeric\n",
    "data['month'] = [strptime(str(x), '%b').tm_mon for x in data['month']]\n",
    "\n",
    "#change all object data type to categorical\n",
    "list_str_obj_cols = data.columns[data.dtypes == \"object\"].tolist()\n",
    "for str_obj_col in list_str_obj_cols:\n",
    "    data[str_obj_col] = data[str_obj_col].astype(\"category\")\n",
    "\n",
    "#encode all categorical data\n",
    "df_encoded = pd.get_dummies(data, columns=['job', 'marital', 'education', 'default', \n",
    "                                           'housing', 'loan', 'contact', 'poutcome'],)\n",
    "\n",
    "\n",
    "#standardize all numeric data\n",
    "data_numeric = data[[\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"month\"]]\n",
    " \n",
    "std_scaler = StandardScaler()\n",
    "df_scaled = std_scaler.fit_transform(data_numeric.to_numpy())\n",
    "df_scaled = pd.DataFrame(df_scaled, columns = [\"age\", \"balance\", \"day\", \"duration\", \"campaign\", \"pdays\", \"previous\", \"month\"])\n",
    " \n",
    "#combine both datasets\n",
    "df_encoded.update(df_scaled)\n",
    "\n",
    "#change class label to 0 and 1\n",
    "df_encoded.y = pd.Categorical(df_encoded.y).codes\n",
    "newdata = df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2032ba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>balance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>y</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>job_blue-collar</th>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <th>job_housemaid</th>\n",
       "      <th>job_management</th>\n",
       "      <th>job_retired</th>\n",
       "      <th>job_self-employed</th>\n",
       "      <th>job_services</th>\n",
       "      <th>job_student</th>\n",
       "      <th>job_technician</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>job_unknown</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>education_primary</th>\n",
       "      <th>education_secondary</th>\n",
       "      <th>education_tertiary</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>default_no</th>\n",
       "      <th>default_yes</th>\n",
       "      <th>housing_no</th>\n",
       "      <th>housing_yes</th>\n",
       "      <th>loan_no</th>\n",
       "      <th>loan_yes</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_other</th>\n",
       "      <th>poutcome_success</th>\n",
       "      <th>poutcome_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.606965</td>\n",
       "      <td>0.256419</td>\n",
       "      <td>-1.298476</td>\n",
       "      <td>-0.475354</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288529</td>\n",
       "      <td>-0.437895</td>\n",
       "      <td>-1.298476</td>\n",
       "      <td>-0.475354</td>\n",
       "      <td>-0.416127</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.747384</td>\n",
       "      <td>-0.446762</td>\n",
       "      <td>-1.298476</td>\n",
       "      <td>-0.475354</td>\n",
       "      <td>-0.707361</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.571051</td>\n",
       "      <td>0.047205</td>\n",
       "      <td>-1.298476</td>\n",
       "      <td>-0.475354</td>\n",
       "      <td>-0.645231</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.747384</td>\n",
       "      <td>-0.447091</td>\n",
       "      <td>-1.298476</td>\n",
       "      <td>-0.475354</td>\n",
       "      <td>-0.233620</td>\n",
       "      <td>-0.569351</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45206</th>\n",
       "      <td>0.947747</td>\n",
       "      <td>-0.176460</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>2.016333</td>\n",
       "      <td>2.791329</td>\n",
       "      <td>0.076230</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45207</th>\n",
       "      <td>2.831227</td>\n",
       "      <td>0.120447</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>2.016333</td>\n",
       "      <td>0.768224</td>\n",
       "      <td>-0.246560</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45208</th>\n",
       "      <td>2.925401</td>\n",
       "      <td>1.429593</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>2.016333</td>\n",
       "      <td>3.373797</td>\n",
       "      <td>0.721811</td>\n",
       "      <td>1.436189</td>\n",
       "      <td>1.050473</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45209</th>\n",
       "      <td>1.512791</td>\n",
       "      <td>-0.228024</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>2.016333</td>\n",
       "      <td>0.970146</td>\n",
       "      <td>0.399020</td>\n",
       "      <td>-0.411453</td>\n",
       "      <td>-0.251940</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45210</th>\n",
       "      <td>-0.370689</td>\n",
       "      <td>0.528364</td>\n",
       "      <td>0.143418</td>\n",
       "      <td>2.016333</td>\n",
       "      <td>0.399328</td>\n",
       "      <td>-0.246560</td>\n",
       "      <td>1.476138</td>\n",
       "      <td>4.523577</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45211 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age   balance       day     month  duration  campaign     pdays  \\\n",
       "0      1.606965  0.256419 -1.298476 -0.475354  0.011016 -0.569351 -0.411453   \n",
       "1      0.288529 -0.437895 -1.298476 -0.475354 -0.416127 -0.569351 -0.411453   \n",
       "2     -0.747384 -0.446762 -1.298476 -0.475354 -0.707361 -0.569351 -0.411453   \n",
       "3      0.571051  0.047205 -1.298476 -0.475354 -0.645231 -0.569351 -0.411453   \n",
       "4     -0.747384 -0.447091 -1.298476 -0.475354 -0.233620 -0.569351 -0.411453   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "45206  0.947747 -0.176460  0.143418  2.016333  2.791329  0.076230 -0.411453   \n",
       "45207  2.831227  0.120447  0.143418  2.016333  0.768224 -0.246560 -0.411453   \n",
       "45208  2.925401  1.429593  0.143418  2.016333  3.373797  0.721811  1.436189   \n",
       "45209  1.512791 -0.228024  0.143418  2.016333  0.970146  0.399020 -0.411453   \n",
       "45210 -0.370689  0.528364  0.143418  2.016333  0.399328 -0.246560  1.476138   \n",
       "\n",
       "       previous  y  job_admin.  job_blue-collar  job_entrepreneur  \\\n",
       "0     -0.251940  0       False            False             False   \n",
       "1     -0.251940  0       False            False             False   \n",
       "2     -0.251940  0       False            False              True   \n",
       "3     -0.251940  0       False             True             False   \n",
       "4     -0.251940  0       False            False             False   \n",
       "...         ... ..         ...              ...               ...   \n",
       "45206 -0.251940  1       False            False             False   \n",
       "45207 -0.251940  1       False            False             False   \n",
       "45208  1.050473  1       False            False             False   \n",
       "45209 -0.251940  0       False             True             False   \n",
       "45210  4.523577  0       False            False              True   \n",
       "\n",
       "       job_housemaid  job_management  job_retired  job_self-employed  \\\n",
       "0              False            True        False              False   \n",
       "1              False           False        False              False   \n",
       "2              False           False        False              False   \n",
       "3              False           False        False              False   \n",
       "4              False           False        False              False   \n",
       "...              ...             ...          ...                ...   \n",
       "45206          False           False        False              False   \n",
       "45207          False           False         True              False   \n",
       "45208          False           False         True              False   \n",
       "45209          False           False        False              False   \n",
       "45210          False           False        False              False   \n",
       "\n",
       "       job_services  job_student  job_technician  job_unemployed  job_unknown  \\\n",
       "0             False        False           False           False        False   \n",
       "1             False        False            True           False        False   \n",
       "2             False        False           False           False        False   \n",
       "3             False        False           False           False        False   \n",
       "4             False        False           False           False         True   \n",
       "...             ...          ...             ...             ...          ...   \n",
       "45206         False        False            True           False        False   \n",
       "45207         False        False           False           False        False   \n",
       "45208         False        False           False           False        False   \n",
       "45209         False        False           False           False        False   \n",
       "45210         False        False           False           False        False   \n",
       "\n",
       "       marital_divorced  marital_married  marital_single  education_primary  \\\n",
       "0                 False             True           False              False   \n",
       "1                 False            False            True              False   \n",
       "2                 False             True           False              False   \n",
       "3                 False             True           False              False   \n",
       "4                 False            False            True              False   \n",
       "...                 ...              ...             ...                ...   \n",
       "45206             False             True           False              False   \n",
       "45207              True            False           False               True   \n",
       "45208             False             True           False              False   \n",
       "45209             False             True           False              False   \n",
       "45210             False             True           False              False   \n",
       "\n",
       "       education_secondary  education_tertiary  education_unknown  default_no  \\\n",
       "0                    False                True              False        True   \n",
       "1                     True               False              False        True   \n",
       "2                     True               False              False        True   \n",
       "3                    False               False               True        True   \n",
       "4                    False               False               True        True   \n",
       "...                    ...                 ...                ...         ...   \n",
       "45206                False                True              False        True   \n",
       "45207                False               False              False        True   \n",
       "45208                 True               False              False        True   \n",
       "45209                 True               False              False        True   \n",
       "45210                 True               False              False        True   \n",
       "\n",
       "       default_yes  housing_no  housing_yes  loan_no  loan_yes  \\\n",
       "0            False       False         True     True     False   \n",
       "1            False       False         True     True     False   \n",
       "2            False       False         True    False      True   \n",
       "3            False       False         True     True     False   \n",
       "4            False        True        False     True     False   \n",
       "...            ...         ...          ...      ...       ...   \n",
       "45206        False        True        False     True     False   \n",
       "45207        False        True        False     True     False   \n",
       "45208        False        True        False     True     False   \n",
       "45209        False        True        False     True     False   \n",
       "45210        False        True        False     True     False   \n",
       "\n",
       "       contact_cellular  contact_telephone  contact_unknown  poutcome_failure  \\\n",
       "0                 False              False             True             False   \n",
       "1                 False              False             True             False   \n",
       "2                 False              False             True             False   \n",
       "3                 False              False             True             False   \n",
       "4                 False              False             True             False   \n",
       "...                 ...                ...              ...               ...   \n",
       "45206              True              False            False             False   \n",
       "45207              True              False            False             False   \n",
       "45208              True              False            False             False   \n",
       "45209             False               True            False             False   \n",
       "45210              True              False            False             False   \n",
       "\n",
       "       poutcome_other  poutcome_success  poutcome_unknown  \n",
       "0               False             False              True  \n",
       "1               False             False              True  \n",
       "2               False             False              True  \n",
       "3               False             False              True  \n",
       "4               False             False              True  \n",
       "...               ...               ...               ...  \n",
       "45206           False             False              True  \n",
       "45207           False             False              True  \n",
       "45208           False              True             False  \n",
       "45209           False             False              True  \n",
       "45210            True             False             False  \n",
       "\n",
       "[45211 rows x 41 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c7db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newdata.drop([\"y\"], axis=1)\n",
    "y = newdata[\"y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ee0d9b",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a2eb6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([39.75194669, 40.08258176, 40.28624725, 41.24296498, 42.06954074]),\n",
       " 'score_time': array([0.0150857 , 0.01521826, 0.01189208, 0.01546001, 0.02760506]),\n",
       " 'test_MCC': array([ 0.10817797, -0.0078684 ,  0.00468848, -0.05339727,  0.32783922]),\n",
       " 'train_MCC': array([0.66183437, 0.70592128, 0.69916156, 0.73768746, 0.72126897]),\n",
       " 'test_Accuracy': array([0.88455159, 0.79882769, 0.78522451, 0.58493696, 0.70957753]),\n",
       " 'train_Accuracy': array([0.93394714, 0.94191158, 0.94218806, 0.9478559 , 0.94730294])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "\n",
    "\n",
    "#mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "model = MLPClassifier() \n",
    "cv_results = cross_validate(model, X, y, cv=5, \n",
    "                            return_train_score=True, \n",
    "                            scoring= {\"MCC\": make_scorer(matthews_corrcoef), \"Accuracy\": \"accuracy\"}) \n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63da293c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MCC: 0.705174729099817\n",
      "test MCC: 0.07588800069440707\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"train MCC:\",np.mean(cv_results['train_MCC']))\n",
    "print(\"test MCC:\",np.mean(cv_results['test_MCC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c91fefc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MCC: 0.8922334745670332\n",
      "Test MCC: 0.47698554539196464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize the nn model\n",
    "model = MLPClassifier() \n",
    "\n",
    "# Initialize Stratified KFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# For storing results\n",
    "train_mcc_scores = []\n",
    "test_mcc_scores = []\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    \n",
    "    # Apply SMOTE only to the training set\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict and compute MCC for the training data\n",
    "    train_preds = model.predict(X_train_resampled)\n",
    "    train_mcc = matthews_corrcoef(y_train_resampled, train_preds)\n",
    "    train_mcc_scores.append(train_mcc)\n",
    "    \n",
    "    # Predict and compute MCC for the testing data\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_mcc = matthews_corrcoef(y_test, test_preds)\n",
    "    test_mcc_scores.append(test_mcc)\n",
    "\n",
    "# Print the average MCC scores\n",
    "print(\"Train MCC:\", np.mean(train_mcc_scores))\n",
    "print(\"Test MCC:\", np.mean(test_mcc_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162cea2a",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61bd969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used for parameter tuning\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, train_size = .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43af2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote on training dataset\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e96143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "270 fits failed out of a total of 810.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "62 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'tanh', 'logistic', 'identity', 'relu'}. Got 'Tanh' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "99 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'logistic', 'tanh', 'identity', 'relu'}. Got 'Tanh' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'tanh', 'identity', 'logistic', 'relu'}. Got 'Tanh' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1145, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 638, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'activation' parameter of MLPClassifier must be a str among {'relu', 'tanh', 'logistic', 'identity'}. Got 'Tanh' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ZHANG FANYUE\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.82063003 0.84224871 0.77202264 0.79435908 0.70983694 0.74421903\n",
      " 0.81250336 0.82248893 0.78070499 0.79353974 0.71015954 0.7557146\n",
      " 0.79742005 0.80142645 0.77839745 0.7883783  0.65859653 0.73636674\n",
      " 0.82216749 0.83946561 0.77305335 0.79266946 0.70811063 0.74400295\n",
      " 0.80513624 0.82366153 0.77847618 0.7875581  0.71299206 0.7561831\n",
      " 0.8094844  0.79789534 0.77778538 0.78463908 0.6885442  0.68959332\n",
      " 0.81448776 0.82494527 0.77226191 0.78808647 0.70910435 0.74316147\n",
      " 0.81727251 0.80933547 0.77905815 0.78848573 0.7129327  0.75685951\n",
      " 0.80179915 0.80278792 0.77966728 0.78191462 0.6268818  0.67169903\n",
      " 0.84111977 0.8460158  0.81868694 0.82925496 0.7426681  0.78131376\n",
      " 0.84230439 0.85099259 0.82370848 0.83558018 0.76305332 0.80125354\n",
      " 0.82598824 0.81897074 0.80849099 0.81624668 0.74430289 0.77871246\n",
      " 0.83857073 0.84680722 0.81629983 0.82984957 0.74276068 0.78143735\n",
      " 0.84496416 0.84939006 0.82393279 0.83111462 0.76684482 0.79826076\n",
      " 0.82681265 0.82441468 0.80496803 0.81330899 0.74474129 0.78051108\n",
      " 0.83643288 0.83863806 0.81641531 0.82916321 0.74282655 0.78507162\n",
      " 0.8397343  0.83638376 0.82628453 0.83420767 0.76387233 0.79671486\n",
      " 0.82957955 0.82749713 0.80713508 0.81265445 0.7405441  0.78461694\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;logistic&#x27;, &#x27;relu&#x27;, &#x27;Tanh&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.001, 0.0001, 0.01],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [100, (50, 50), (20, 20, 20)],\n",
       "                         &#x27;learning_rate_init&#x27;: [0.001, 0.0001, 1e-05],\n",
       "                         &#x27;max_iter&#x27;: [200, 500]},\n",
       "             scoring=make_scorer(matthews_corrcoef), verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;activation&#x27;: [&#x27;logistic&#x27;, &#x27;relu&#x27;, &#x27;Tanh&#x27;],\n",
       "                         &#x27;alpha&#x27;: [0.001, 0.0001, 0.01],\n",
       "                         &#x27;hidden_layer_sizes&#x27;: [100, (50, 50), (20, 20, 20)],\n",
       "                         &#x27;learning_rate_init&#x27;: [0.001, 0.0001, 1e-05],\n",
       "                         &#x27;max_iter&#x27;: [200, 500]},\n",
       "             scoring=make_scorer(matthews_corrcoef), verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=-1,\n",
       "             param_grid={'activation': ['logistic', 'relu', 'Tanh'],\n",
       "                         'alpha': [0.001, 0.0001, 0.01],\n",
       "                         'hidden_layer_sizes': [100, (50, 50), (20, 20, 20)],\n",
       "                         'learning_rate_init': [0.001, 0.0001, 1e-05],\n",
       "                         'max_iter': [200, 500]},\n",
       "             scoring=make_scorer(matthews_corrcoef), verbose=2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import make_scorer, matthews_corrcoef\n",
    "\n",
    "model = MLPClassifier() \n",
    "parameters={\n",
    "'hidden_layer_sizes': [(100), (50,50), (20,20,20)],\n",
    "'alpha': [0.001, 0.0001, 0.01],\n",
    "'activation': [\"logistic\", \"relu\", \"Tanh\"],\n",
    "'learning_rate_init': [0.001, 0.0001, 0.00001],\n",
    "'max_iter':[200, 500]\n",
    "}\n",
    "\n",
    "tuning = GridSearchCV(estimator=model,param_grid=parameters,n_jobs=-1,verbose=2,cv=5, refit=True,\n",
    "                      scoring = make_scorer(matthews_corrcoef))\n",
    "tuning.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2768c913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4405717288120462"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = tuning.predict(X_test) #predict using test data\n",
    "matthews_corrcoef(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0f336ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (50, 50), 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "Best Score:  0.8509925933085917\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", tuning.best_params_)\n",
    "print(\"Best Score: \", tuning.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bfcc0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([1.21855096e+02, 3.16475309e+02, 1.24259650e+02, 3.12925141e+02,\n",
       "        1.31781701e+02, 3.20252765e+02, 1.58460001e+02, 2.96449528e+02,\n",
       "        1.58207903e+02, 3.56672037e+02, 1.55544811e+02, 3.85098110e+02,\n",
       "        1.14883454e+02, 1.28828140e+02, 1.19807325e+02, 2.57156225e+02,\n",
       "        9.79276225e+01, 3.08389128e+02, 1.27901444e+02, 3.16182273e+02,\n",
       "        1.30404039e+02, 3.15640165e+02, 1.29483182e+02, 3.24637975e+02,\n",
       "        1.53911017e+02, 3.67038201e+02, 1.57971160e+02, 3.23591070e+02,\n",
       "        1.57089520e+02, 3.82026189e+02, 1.21486761e+02, 1.26033466e+02,\n",
       "        1.23149637e+02, 2.29668730e+02, 1.20098554e+02, 2.42522604e+02,\n",
       "        1.28164568e+02, 2.28871696e+02, 1.29773295e+02, 2.87685947e+02,\n",
       "        1.28061751e+02, 3.14874921e+02, 1.59332596e+02, 1.85271664e+02,\n",
       "        1.55851072e+02, 3.19084465e+02, 1.57149929e+02, 3.91641411e+02,\n",
       "        1.07267647e+02, 1.04787853e+02, 1.19256292e+02, 2.18340974e+02,\n",
       "        9.62599054e+01, 2.39133643e+02, 1.38618582e+02, 1.71395604e+02,\n",
       "        1.37306137e+02, 3.01646968e+02, 1.22725455e+02, 3.03454502e+02,\n",
       "        3.19139492e+02, 5.36021417e+02, 2.02904689e+02, 8.82285422e+02,\n",
       "        1.40777228e+02, 3.60424619e+02, 2.71149175e+02, 2.00787414e+02,\n",
       "        1.59686314e+02, 4.19824336e+02, 1.10310834e+02, 2.83341764e+02,\n",
       "        1.26052761e+02, 1.76377080e+02, 1.16852607e+02, 3.01725019e+02,\n",
       "        1.21120177e+02, 3.01372946e+02, 3.15525767e+02, 2.71277519e+02,\n",
       "        1.46269553e+02, 3.38352216e+02, 1.51762270e+02, 3.61702170e+02,\n",
       "        2.60189623e+02, 2.59410448e+02, 1.14180170e+02, 2.11399759e+02,\n",
       "        1.14790054e+02, 2.93474542e+02, 1.26956054e+02, 1.86386248e+02,\n",
       "        1.20446115e+02, 2.71377923e+02, 1.22008348e+02, 2.96882765e+02,\n",
       "        2.90229866e+02, 3.44238429e+02, 2.02571035e+02, 5.89447893e+02,\n",
       "        1.66437660e+02, 6.59109060e+02, 2.91878674e+02, 2.50243379e+02,\n",
       "        2.16456697e+02, 3.63268613e+02, 1.21151867e+02, 3.42164263e+02,\n",
       "        7.28029251e-02, 8.94385338e-02, 6.82205200e-02, 1.03972578e-01,\n",
       "        6.90258026e-02, 1.00568628e-01, 9.74396229e-02, 9.35774326e-02,\n",
       "        8.71892452e-02, 1.19810057e-01, 9.45104122e-02, 8.24083805e-02,\n",
       "        7.68625259e-02, 1.01229143e-01, 1.07154226e-01, 5.04080296e-02,\n",
       "        5.39752960e-02, 6.17702484e-02, 6.77328587e-02, 8.73526573e-02,\n",
       "        5.53805828e-02, 9.49223518e-02, 1.52799129e-02, 2.20322609e-02,\n",
       "        8.17364693e-02, 6.66606426e-02, 8.20420265e-02, 6.07077122e-02,\n",
       "        5.56619167e-02, 9.23973560e-02, 7.10492611e-02, 5.70210457e-02,\n",
       "        1.87523365e-02, 1.15654039e-01, 3.87294292e-02, 1.52855396e-02,\n",
       "        1.57147408e-02, 7.30622768e-02, 5.95611095e-02, 5.67863464e-02,\n",
       "        3.90657425e-02, 6.38944149e-02, 3.14638615e-02, 9.01422977e-02,\n",
       "        7.62263775e-02, 7.97792435e-02, 3.95034790e-02, 1.09523344e-01,\n",
       "        4.11891460e-02, 5.47157764e-02, 6.91612720e-02, 3.47462177e-02,\n",
       "        5.65940380e-02, 7.60787964e-02]),\n",
       " 'std_fit_time': array([3.44727340e+00, 1.38920840e+00, 4.56861629e+00, 5.60487127e+00,\n",
       "        1.97579162e+00, 5.41020504e+00, 2.23277939e+00, 7.88236954e+01,\n",
       "        5.63952310e+00, 5.09782313e+01, 3.58577197e+00, 6.52178652e+00,\n",
       "        1.00532773e+01, 2.43298463e+01, 3.52455001e+00, 3.91783121e+01,\n",
       "        4.43548429e+01, 4.98062439e+00, 8.75177614e-01, 4.23569788e+00,\n",
       "        2.89856689e+00, 2.69552079e+01, 2.63444387e+00, 5.00139807e+00,\n",
       "        2.70826166e+00, 3.51516223e+01, 3.78688104e+00, 4.66318412e+01,\n",
       "        4.35957282e+00, 5.23762906e+00, 2.94576892e+00, 3.69673158e+01,\n",
       "        3.08852684e+00, 4.03725169e+01, 5.87783624e+00, 1.16693454e+02,\n",
       "        3.78864950e+00, 4.90041045e+01, 6.03136899e+00, 3.39773191e+01,\n",
       "        3.36247724e+00, 7.81017417e+00, 4.20237058e+00, 4.74776044e+01,\n",
       "        7.05834130e+00, 5.67237821e+01, 4.38771647e+00, 3.44221017e+00,\n",
       "        2.00645186e+01, 9.39142916e+00, 2.94745849e+00, 5.21158875e+01,\n",
       "        4.47896587e+01, 1.15157887e+02, 2.63500911e+01, 1.35228089e+01,\n",
       "        2.09124531e+01, 1.40238320e+01, 2.80389312e+00, 7.66533098e+00,\n",
       "        1.24585872e+02, 4.01802360e+02, 7.74577870e+01, 5.16987432e+02,\n",
       "        7.70104649e+00, 9.93227194e+00, 1.36242436e+02, 9.23008437e+01,\n",
       "        2.52993778e+01, 1.10903183e+02, 4.72375702e+00, 2.47316343e+00,\n",
       "        2.04327766e+01, 2.05658086e+01, 5.39647697e+00, 1.50540631e+01,\n",
       "        8.87094586e+00, 6.50226815e+00, 1.61445312e+02, 1.22630549e+02,\n",
       "        8.95076546e+00, 3.06957029e+01, 4.92684989e+00, 1.37096823e+01,\n",
       "        1.06529617e+02, 7.13522365e+01, 2.92469319e+00, 3.66521107e+01,\n",
       "        7.12306078e+00, 6.09950550e+00, 2.39846822e+01, 7.26282606e+01,\n",
       "        5.81847190e+00, 1.19096115e+01, 4.52925196e+00, 4.97005168e+00,\n",
       "        1.50677886e+02, 1.67739187e+02, 6.64551867e+01, 3.24568626e+02,\n",
       "        4.01249109e+01, 2.67289466e+02, 1.22191496e+02, 1.12621229e+02,\n",
       "        3.54668733e+01, 2.40519252e+01, 1.23273439e+01, 7.70012269e+01,\n",
       "        4.78518550e-02, 9.29489859e-02, 5.44724949e-02, 6.36658334e-02,\n",
       "        6.56328333e-02, 7.41787267e-02, 6.78118260e-02, 6.50961441e-02,\n",
       "        5.56338300e-02, 5.52200956e-02, 6.62147183e-02, 8.48349441e-02,\n",
       "        6.69856400e-02, 6.31354965e-02, 5.17532255e-02, 4.28737095e-02,\n",
       "        4.78834435e-02, 3.95889382e-02, 6.41607032e-02, 6.23542543e-02,\n",
       "        4.30782107e-02, 7.54161680e-02, 6.37734316e-04, 7.69012483e-03,\n",
       "        6.85902109e-02, 5.62266768e-02, 7.59352834e-02, 4.74880149e-02,\n",
       "        4.91742315e-02, 5.61874304e-02, 6.95506586e-02, 5.08984891e-02,\n",
       "        6.25169341e-03, 4.66648478e-02, 3.62250463e-02, 1.59469561e-03,\n",
       "        4.32008744e-04, 4.77196557e-02, 5.02214495e-02, 4.53833727e-02,\n",
       "        4.87022368e-02, 5.31137765e-02, 3.22371104e-02, 6.09413921e-02,\n",
       "        4.98362888e-02, 5.03317410e-02, 4.04430903e-02, 4.98221684e-02,\n",
       "        4.36401598e-02, 4.64500038e-02, 4.60182314e-02, 3.77178164e-02,\n",
       "        5.04136566e-02, 4.82538683e-02]),\n",
       " 'mean_score_time': array([0.11100621, 0.09947815, 0.14489636, 0.085988  , 0.07100506,\n",
       "        0.10195498, 0.0721458 , 0.09126654, 0.11913419, 0.0918705 ,\n",
       "        0.15139642, 0.0996048 , 0.04154668, 0.07944589, 0.07093782,\n",
       "        0.09630852, 0.12655339, 0.13792791, 0.11581516, 0.13420396,\n",
       "        0.12768445, 0.13184619, 0.17437582, 0.08848081, 0.13618722,\n",
       "        0.06089535, 0.06845093, 0.0770968 , 0.15636835, 0.10623884,\n",
       "        0.07278304, 0.02596688, 0.10793314, 0.09872332, 0.1120625 ,\n",
       "        0.13067603, 0.12215085, 0.12057214, 0.10090051, 0.12303276,\n",
       "        0.15415635, 0.11458516, 0.16792903, 0.03461585, 0.17356696,\n",
       "        0.19929676, 0.18983359, 0.17892084, 0.14337234, 0.02551737,\n",
       "        0.09155612, 0.05244803, 0.0985034 , 0.01994767, 0.12517781,\n",
       "        0.08157911, 0.03041444, 0.01820769, 0.10267577, 0.0770021 ,\n",
       "        0.37234278, 0.30504537, 0.24462767, 0.29371772, 0.07066941,\n",
       "        0.080689  , 0.22118711, 0.14883747, 0.11911106, 0.14488978,\n",
       "        0.09416828, 0.04768448, 0.09126616, 0.07770257, 0.04590826,\n",
       "        0.01934915, 0.1474072 , 0.05193315, 0.65731049, 0.07804632,\n",
       "        0.0554214 , 0.05502725, 0.04307203, 0.03915181, 0.11798925,\n",
       "        0.22583985, 0.04569035, 0.05381851, 0.06605186, 0.10745502,\n",
       "        0.08508592, 0.10138822, 0.12676544, 0.04302607, 0.06929622,\n",
       "        0.074051  , 0.33675795, 0.31869874, 0.14410038, 0.13168087,\n",
       "        0.17061129, 0.13304362, 0.33738666, 0.33518829, 0.21658635,\n",
       "        0.12382131, 0.13402567, 0.0800662 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " 'std_score_time': array([0.09265722, 0.03961084, 0.06759809, 0.04032893, 0.04907645,\n",
       "        0.05917999, 0.03104958, 0.04788184, 0.05251715, 0.04582182,\n",
       "        0.05582793, 0.0398167 , 0.03140822, 0.05419526, 0.03789231,\n",
       "        0.07685371, 0.11473268, 0.07779634, 0.04274977, 0.06526256,\n",
       "        0.02901909, 0.05518039, 0.07202817, 0.06762722, 0.05196352,\n",
       "        0.05166915, 0.06292493, 0.0508658 , 0.02098102, 0.06075468,\n",
       "        0.06072883, 0.00098806, 0.06824705, 0.05975014, 0.0667949 ,\n",
       "        0.05657168, 0.04477618, 0.04412541, 0.03843791, 0.09024619,\n",
       "        0.063002  , 0.06360196, 0.02514163, 0.00077116, 0.08413845,\n",
       "        0.12543419, 0.06034759, 0.10895388, 0.07826675, 0.00049003,\n",
       "        0.07586417, 0.06058759, 0.04829073, 0.00398232, 0.08483195,\n",
       "        0.07687018, 0.02522643, 0.00689808, 0.05999072, 0.07412377,\n",
       "        0.23113243, 0.38939139, 0.23584186, 0.20177813, 0.0662281 ,\n",
       "        0.07010607, 0.1790015 , 0.11313576, 0.072612  , 0.09598348,\n",
       "        0.06435558, 0.05547215, 0.09743427, 0.06688323, 0.05542966,\n",
       "        0.0065659 , 0.07095694, 0.06065997, 0.46594883, 0.06543455,\n",
       "        0.07458465, 0.06284276, 0.04276615, 0.03060125, 0.07291166,\n",
       "        0.09313314, 0.06378185, 0.0595598 , 0.06119607, 0.07319241,\n",
       "        0.12257361, 0.04648402, 0.09163658, 0.04951905, 0.06879452,\n",
       "        0.07179393, 0.3333204 , 0.33346816, 0.15957942, 0.07694985,\n",
       "        0.14767517, 0.09338169, 0.2567198 , 0.16545857, 0.1013418 ,\n",
       "        0.08964947, 0.06101701, 0.03529841, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        ]),\n",
       " 'param_activation': masked_array(data=['logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
       "                    'logistic', 'logistic', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
       "                    'relu', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh',\n",
       "                    'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh', 'Tanh'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001, 0.0001,\n",
       "                    0.0001, 0.0001, 0.0001, 0.0001, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_hidden_layer_sizes': masked_array(data=[100, 100, 100, 100, 100, 100, (50, 50), (50, 50),\n",
       "                    (50, 50), (50, 50), (50, 50), (50, 50), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), 100, 100, 100, 100, 100, 100, (50, 50),\n",
       "                    (50, 50), (50, 50), (50, 50), (50, 50), (50, 50),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), 100, 100, 100, 100, 100,\n",
       "                    100, (50, 50), (50, 50), (50, 50), (50, 50), (50, 50),\n",
       "                    (50, 50), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), 100, 100,\n",
       "                    100, 100, 100, 100, (50, 50), (50, 50), (50, 50),\n",
       "                    (50, 50), (50, 50), (50, 50), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), 100, 100, 100, 100, 100, 100, (50, 50),\n",
       "                    (50, 50), (50, 50), (50, 50), (50, 50), (50, 50),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), 100, 100, 100, 100, 100,\n",
       "                    100, (50, 50), (50, 50), (50, 50), (50, 50), (50, 50),\n",
       "                    (50, 50), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), 100, 100,\n",
       "                    100, 100, 100, 100, (50, 50), (50, 50), (50, 50),\n",
       "                    (50, 50), (50, 50), (50, 50), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), 100, 100, 100, 100, 100, 100, (50, 50),\n",
       "                    (50, 50), (50, 50), (50, 50), (50, 50), (50, 50),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), 100, 100, 100, 100, 100,\n",
       "                    100, (50, 50), (50, 50), (50, 50), (50, 50), (50, 50),\n",
       "                    (50, 50), (20, 20, 20), (20, 20, 20), (20, 20, 20),\n",
       "                    (20, 20, 20), (20, 20, 20), (20, 20, 20)],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate_init': masked_array(data=[0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05,\n",
       "                    1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05,\n",
       "                    1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05,\n",
       "                    1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05,\n",
       "                    0.001, 0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001,\n",
       "                    0.001, 0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001,\n",
       "                    0.0001, 0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001,\n",
       "                    0.0001, 1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001,\n",
       "                    1e-05, 1e-05, 0.001, 0.001, 0.0001, 0.0001, 1e-05,\n",
       "                    1e-05],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_iter': masked_array(data=[200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'logistic',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'relu',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.0001,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': 100,\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (50, 50),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 0.0001,\n",
       "   'max_iter': 500},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 200},\n",
       "  {'activation': 'Tanh',\n",
       "   'alpha': 0.01,\n",
       "   'hidden_layer_sizes': (20, 20, 20),\n",
       "   'learning_rate_init': 1e-05,\n",
       "   'max_iter': 500}],\n",
       " 'split0_test_score': array([0.63102764, 0.66071697, 0.62870725, 0.62386518, 0.65826306,\n",
       "        0.65244109, 0.62498591, 0.61274056, 0.61663252, 0.60478834,\n",
       "        0.66060907, 0.64160686, 0.61808556, 0.60571752, 0.61622305,\n",
       "        0.60750626, 0.65445555, 0.65644163, 0.63264793, 0.66196709,\n",
       "        0.6278655 , 0.6206787 , 0.65794176, 0.65241568, 0.60392615,\n",
       "        0.61156856, 0.60655832, 0.593216  , 0.66082384, 0.64869859,\n",
       "        0.63635594, 0.5735747 , 0.61632516, 0.5958086 , 0.65518567,\n",
       "        0.65775291, 0.62960199, 0.638901  , 0.63306579, 0.62865309,\n",
       "        0.65811255, 0.65302575, 0.63291735, 0.5958137 , 0.62382586,\n",
       "        0.61628259, 0.65858099, 0.6439141 , 0.61123936, 0.62235323,\n",
       "        0.6225421 , 0.60202801, 0.64864383, 0.65852599, 0.64948677,\n",
       "        0.66883059, 0.64491336, 0.6413842 , 0.67766916, 0.66131562,\n",
       "        0.66358375, 0.68089709, 0.63700044, 0.66155503, 0.66881535,\n",
       "        0.65084322, 0.6506126 , 0.63005698, 0.64205707, 0.63772825,\n",
       "        0.66173363, 0.63798727, 0.64892227, 0.67576444, 0.63639626,\n",
       "        0.63812173, 0.67364081, 0.66720128, 0.66567159, 0.65810573,\n",
       "        0.64343772, 0.64152319, 0.67526681, 0.64798993, 0.65358413,\n",
       "        0.63804511, 0.62238771, 0.625335  , 0.67150092, 0.65750304,\n",
       "        0.6756723 , 0.65180058, 0.63533672, 0.64513524, 0.67695701,\n",
       "        0.66933278, 0.63807922, 0.64288005, 0.64469564, 0.65212438,\n",
       "        0.6678483 , 0.64395382, 0.66034726, 0.6604635 , 0.61731122,\n",
       "        0.62406998, 0.67688139, 0.64308806,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'split1_test_score': array([0.87201831, 0.88559312, 0.80665127, 0.83730473, 0.72297929,\n",
       "        0.7662831 , 0.86679038, 0.87754993, 0.81796815, 0.83617998,\n",
       "        0.73342415, 0.78015405, 0.84465178, 0.84331456, 0.8153713 ,\n",
       "        0.83542367, 0.70967075, 0.75731086, 0.86799082, 0.88066775,\n",
       "        0.8073577 , 0.83712322, 0.72405725, 0.7678917 , 0.8638178 ,\n",
       "        0.88191206, 0.82259463, 0.83101078, 0.73627419, 0.79058147,\n",
       "        0.85173458, 0.84313767, 0.81962803, 0.83343932, 0.70930983,\n",
       "        0.5062617 , 0.85768294, 0.86369357, 0.80678324, 0.82370286,\n",
       "        0.72120114, 0.76411542, 0.86921002, 0.87382068, 0.81551745,\n",
       "        0.82335341, 0.72964339, 0.79138404, 0.85196849, 0.85153426,\n",
       "        0.81491952, 0.82605329, 0.69357754, 0.43183683, 0.88924762,\n",
       "        0.89864933, 0.86587812, 0.87460933, 0.75807267, 0.80984946,\n",
       "        0.88746111, 0.90046416, 0.87200124, 0.88227334, 0.78253147,\n",
       "        0.83782285, 0.87848815, 0.87202278, 0.85095447, 0.85763632,\n",
       "        0.75751187, 0.81393925, 0.89273161, 0.88354523, 0.86172163,\n",
       "        0.87721209, 0.76132916, 0.81117544, 0.9001315 , 0.89819321,\n",
       "        0.86920747, 0.87690386, 0.79336404, 0.83591402, 0.87651513,\n",
       "        0.87690432, 0.85123651, 0.86571155, 0.76190364, 0.80731476,\n",
       "        0.87448359, 0.88535863, 0.86118248, 0.87647894, 0.76161413,\n",
       "        0.81752199, 0.88611355, 0.89181105, 0.87467588, 0.88285486,\n",
       "        0.78639174, 0.83906872, 0.86779756, 0.87104787, 0.85691456,\n",
       "        0.86457056, 0.75381074, 0.82077421,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'split2_test_score': array([0.86814903, 0.89409574, 0.80507419, 0.83939364, 0.71565561,\n",
       "        0.76271641, 0.8607928 , 0.8741623 , 0.82289854, 0.83609265,\n",
       "        0.70387514, 0.78019273, 0.84075171, 0.85433416, 0.82288499,\n",
       "        0.83715376, 0.68153769, 0.75660588, 0.8733742 , 0.88365616,\n",
       "        0.80675275, 0.83729384, 0.71062034, 0.7628695 , 0.86246676,\n",
       "        0.87929277, 0.82129619, 0.83076375, 0.7168148 , 0.79330239,\n",
       "        0.85403037, 0.86032124, 0.82295287, 0.83018036, 0.69609228,\n",
       "        0.74482547, 0.85651287, 0.87032796, 0.80359868, 0.82682254,\n",
       "        0.71376197, 0.76320405, 0.86117457, 0.86011545, 0.8169713 ,\n",
       "        0.83204573, 0.71815926, 0.78025383, 0.84172395, 0.8482506 ,\n",
       "        0.81887584, 0.8328294 , 0.41114868, 0.73217247, 0.89248805,\n",
       "        0.87736677, 0.86577961, 0.87569364, 0.75537911, 0.80973091,\n",
       "        0.87796577, 0.89162608, 0.86693495, 0.88254314, 0.79047651,\n",
       "        0.83272324, 0.87452698, 0.86679362, 0.85689082, 0.86142573,\n",
       "        0.76359284, 0.81326232, 0.88849435, 0.89637273, 0.86284169,\n",
       "        0.87733433, 0.75103958, 0.80596584, 0.88813959, 0.89491988,\n",
       "        0.86892548, 0.88096627, 0.7861679 , 0.83377711, 0.8714114 ,\n",
       "        0.87319856, 0.85228642, 0.8593441 , 0.75145737, 0.80998003,\n",
       "        0.86756753, 0.88709623, 0.86331182, 0.88215678, 0.75214921,\n",
       "        0.81229231, 0.88631713, 0.89031309, 0.8738377 , 0.88390306,\n",
       "        0.79313645, 0.83563542, 0.8731145 , 0.87374728, 0.85563401,\n",
       "        0.85069675, 0.75215328, 0.82153285,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'split3_test_score': array([0.86877132, 0.8830975 , 0.80768679, 0.83271655, 0.72280633,\n",
       "        0.76520784, 0.84723354, 0.88042116, 0.8221946 , 0.84381288,\n",
       "        0.72412984, 0.7815563 , 0.84592141, 0.85852383, 0.81655639,\n",
       "        0.82711928, 0.71098951, 0.76010796, 0.8700459 , 0.88383318,\n",
       "        0.81053399, 0.8257255 , 0.71967745, 0.76445855, 0.83710193,\n",
       "        0.86962887, 0.8195073 , 0.8443296 , 0.71644761, 0.76095915,\n",
       "        0.853295  , 0.86518341, 0.82043299, 0.82873284, 0.68982755,\n",
       "        0.76233373, 0.86077141, 0.87504947, 0.80737874, 0.82842933,\n",
       "        0.72296567, 0.76181615, 0.86274356, 0.85086118, 0.81847263,\n",
       "        0.83120345, 0.73301741, 0.78397127, 0.85025522, 0.83653032,\n",
       "        0.81682102, 0.82307848, 0.70801711, 0.76445964, 0.88647344,\n",
       "        0.89090109, 0.85521943, 0.87904353, 0.75395319, 0.80978061,\n",
       "        0.89068963, 0.89369518, 0.86967514, 0.87796366, 0.78242738,\n",
       "        0.84279955, 0.85668393, 0.85699172, 0.84328519, 0.86141299,\n",
       "        0.76656549, 0.81237258, 0.88265188, 0.89151328, 0.86063882,\n",
       "        0.87935317, 0.75767881, 0.80902353, 0.88701653, 0.90072691,\n",
       "        0.86551313, 0.88106718, 0.78888784, 0.83437721, 0.86839338,\n",
       "        0.87042514, 0.85061912, 0.86327726, 0.76319865, 0.80301701,\n",
       "        0.87935623, 0.88790864, 0.85863907, 0.87001208, 0.75319238,\n",
       "        0.81133995, 0.89534324, 0.87929344, 0.8720212 , 0.88347536,\n",
       "        0.77371435, 0.82934663, 0.87211396, 0.86150738, 0.85591272,\n",
       "        0.86397384, 0.75946427, 0.81408299,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'split4_test_score': array([0.86318386, 0.88774021, 0.81199372, 0.8385153 , 0.72948044,\n",
       "        0.77444674, 0.86271418, 0.86757069, 0.82383116, 0.84682485,\n",
       "        0.72875951, 0.79506306, 0.83768978, 0.84524219, 0.82095149,\n",
       "        0.83468856, 0.53632915, 0.7513674 , 0.86677861, 0.88720387,\n",
       "        0.8127568 , 0.84252601, 0.72825633, 0.77237933, 0.85836859,\n",
       "        0.8759054 , 0.82242448, 0.83847037, 0.73459985, 0.78737391,\n",
       "        0.85200612, 0.84725967, 0.80958786, 0.8350343 , 0.69230568,\n",
       "        0.77679278, 0.8678696 , 0.87675434, 0.81048308, 0.83282452,\n",
       "        0.72948044, 0.77364599, 0.86031707, 0.86606637, 0.8205035 ,\n",
       "        0.83954346, 0.72526243, 0.78477432, 0.85380873, 0.8552712 ,\n",
       "        0.82517794, 0.82558389, 0.67302184, 0.77150019, 0.88790297,\n",
       "        0.89433122, 0.8616442 , 0.87554409, 0.76826634, 0.81589222,\n",
       "        0.8918217 , 0.88828046, 0.8729306 , 0.87356573, 0.79101589,\n",
       "        0.84207884, 0.86962954, 0.8689886 , 0.84926741, 0.86303012,\n",
       "        0.77211064, 0.8160009 , 0.88005354, 0.88684042, 0.85990074,\n",
       "        0.87722656, 0.77011506, 0.81382064, 0.8838616 , 0.8950046 ,\n",
       "        0.87258015, 0.87511259, 0.7905375 , 0.8392455 , 0.86415923,\n",
       "        0.86350024, 0.84831036, 0.85287704, 0.77564588, 0.82474053,\n",
       "        0.88508474, 0.88102621, 0.86360647, 0.872033  , 0.77022001,\n",
       "        0.81487105, 0.89281838, 0.87762116, 0.86619221, 0.86868069,\n",
       "        0.79827081, 0.83556969, 0.87452446, 0.87071963, 0.8499029 ,\n",
       "        0.85996113, 0.76041081, 0.8236066 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'mean_test_score': array([0.82063003, 0.84224871, 0.77202264, 0.79435908, 0.70983694,\n",
       "        0.74421903, 0.81250336, 0.82248893, 0.78070499, 0.79353974,\n",
       "        0.71015954, 0.7557146 , 0.79742005, 0.80142645, 0.77839745,\n",
       "        0.7883783 , 0.65859653, 0.73636674, 0.82216749, 0.83946561,\n",
       "        0.77305335, 0.79266946, 0.70811063, 0.74400295, 0.80513624,\n",
       "        0.82366153, 0.77847618, 0.7875581 , 0.71299206, 0.7561831 ,\n",
       "        0.8094844 , 0.79789534, 0.77778538, 0.78463908, 0.6885442 ,\n",
       "        0.68959332, 0.81448776, 0.82494527, 0.77226191, 0.78808647,\n",
       "        0.70910435, 0.74316147, 0.81727251, 0.80933547, 0.77905815,\n",
       "        0.78848573, 0.7129327 , 0.75685951, 0.80179915, 0.80278792,\n",
       "        0.77966728, 0.78191462, 0.6268818 , 0.67169903, 0.84111977,\n",
       "        0.8460158 , 0.81868694, 0.82925496, 0.7426681 , 0.78131376,\n",
       "        0.84230439, 0.85099259, 0.82370848, 0.83558018, 0.76305332,\n",
       "        0.80125354, 0.82598824, 0.81897074, 0.80849099, 0.81624668,\n",
       "        0.74430289, 0.77871246, 0.83857073, 0.84680722, 0.81629983,\n",
       "        0.82984957, 0.74276068, 0.78143735, 0.84496416, 0.84939006,\n",
       "        0.82393279, 0.83111462, 0.76684482, 0.79826076, 0.82681265,\n",
       "        0.82441468, 0.80496803, 0.81330899, 0.74474129, 0.78051108,\n",
       "        0.83643288, 0.83863806, 0.81641531, 0.82916321, 0.74282655,\n",
       "        0.78507162, 0.8397343 , 0.83638376, 0.82628453, 0.83420767,\n",
       "        0.76387233, 0.79671486, 0.82957955, 0.82749713, 0.80713508,\n",
       "        0.81265445, 0.7405441 , 0.78461694,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'std_test_score': array([0.09484333, 0.09083912, 0.07169444, 0.08527799, 0.02615536,\n",
       "        0.04605738, 0.09398836, 0.10496165, 0.08206079, 0.09446981,\n",
       "        0.02674739, 0.05732912, 0.08971439, 0.09801607, 0.08113408,\n",
       "        0.09050139, 0.0645699 , 0.04006237, 0.09478614, 0.08877338,\n",
       "        0.0726266 , 0.08617038, 0.02575713, 0.04590969, 0.10106563,\n",
       "        0.10612616, 0.08596598, 0.09730239, 0.02741179, 0.05497215,\n",
       "        0.0865683 , 0.11245277, 0.08085855, 0.0944419 , 0.01798206,\n",
       "        0.10056818, 0.09252727, 0.09313227, 0.06963236, 0.07977099,\n",
       "        0.02598273, 0.04526041, 0.09223033, 0.10702455, 0.07763371,\n",
       "        0.0862541 , 0.0276264 , 0.05658655, 0.09536978, 0.09043537,\n",
       "        0.07863838, 0.09000133, 0.10970372, 0.12643516, 0.09583717,\n",
       "        0.08887839, 0.08697348, 0.09394741, 0.03288269, 0.06004566,\n",
       "        0.08949305, 0.08514093, 0.09337704, 0.08707443, 0.04726412,\n",
       "        0.07529103, 0.08799506, 0.09459105, 0.08332982, 0.08927684,\n",
       "        0.04155275, 0.07037276, 0.09492763, 0.085631  , 0.08995729,\n",
       "        0.09586737, 0.03510469, 0.05717614, 0.08981625, 0.09566667,\n",
       "        0.09027524, 0.09482387, 0.04584849, 0.07515936, 0.08670782,\n",
       "        0.09328804, 0.09129946, 0.09408713, 0.03741543, 0.06193641,\n",
       "        0.08058611, 0.09344902, 0.09055682, 0.09210846, 0.03357539,\n",
       "        0.05790942, 0.10089206, 0.09691853, 0.09084274, 0.09122083,\n",
       "        0.0487119 , 0.07644491, 0.08464596, 0.08361921, 0.09494376,\n",
       "        0.09442267, 0.03198868, 0.07083643,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan]),\n",
       " 'rank_test_score': array([ 33,   7,  81,  58, 101,  90,  43,  31,  71,  59, 100,  87,  56,\n",
       "         52,  77,  62, 107,  97,  32,  10,  79,  60, 103,  91,  48,  30,\n",
       "         76,  64,  98,  86,  44,  55,  78,  66, 105, 104,  40,  26,  80,\n",
       "         63, 102,  92,  36,  45,  74,  61,  99,  85,  51,  50,  73,  68,\n",
       "        108, 106,   8,   4,  35,  20,  95,  70,   6,   1,  29,  15,  84,\n",
       "         53,  25,  34,  46,  39,  89,  75,  12,   3,  38,  18,  94,  69,\n",
       "          5,   2,  28,  17,  82,  54,  23,  27,  49,  41,  88,  72,  13,\n",
       "         11,  37,  21,  93,  65,   9,  14,  24,  16,  83,  57,  19,  22,\n",
       "         47,  42,  96,  67, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
       "        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
       "        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
       "        109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109,\n",
       "        109, 109, 109, 109, 109, 109])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuning.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e3abedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9545198359269812\n",
      "Test Accuracy: 0.8795753621585757\n",
      "Train Accuracy: 0.9570247675110374\n",
      "Test Accuracy: 0.8754700287547003\n",
      "Train Accuracy: 0.9630221053290751\n",
      "Test Accuracy: 0.8692767086927671\n",
      "Train Accuracy: 0.9528617947272842\n",
      "Test Accuracy: 0.8941605839416058\n",
      "Train Accuracy: 0.9598597282234329\n",
      "Test Accuracy: 0.8730369387303694\n",
      "Train MCC: 0.9153576639780662\n",
      "Test MCC: 0.4531551463959021\n",
      "Train Accuracy_mean: 0.9598597282234329\n",
      "Test Accuracy_mean: 0.8730369387303694\n",
      "Average Train Accuracy: 0.9574576463435622\n",
      "Average Test Accuracy: 0.8783039244556037\n"
     ]
    }
   ],
   "source": [
    "# Initialize the nn model\n",
    "model = MLPClassifier(activation='relu', alpha= 0.0001, \n",
    "                      hidden_layer_sizes= (50, 50), learning_rate_init= 0.001, max_iter= 500) \n",
    "\n",
    "# Initialize Stratified KFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# For storing results\n",
    "train_mcc_scores = []\n",
    "test_mcc_scores = []\n",
    "train_accuracy_scores = []\n",
    "test_accuracy_scores = []\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    \n",
    "    # Apply SMOTE only to the training set\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Predict and compute MCC for the training data\n",
    "    train_preds = model.predict(X_train_resampled)\n",
    "    train_mcc = matthews_corrcoef(y_train_resampled, train_preds)\n",
    "    train_mcc_scores.append(train_mcc)\n",
    "    \n",
    "    # Predict and compute MCC for the testing data\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_mcc = matthews_corrcoef(y_test, test_preds)\n",
    "    test_mcc_scores.append(test_mcc)\n",
    "    accuracy_1 = accuracy_score(y_train_resampled, train_preds)\n",
    "    accuracy_2 = accuracy_score(y_test, test_preds)\n",
    "    train_accuracy_scores.append(accuracy_1)\n",
    "    test_accuracy_scores.append(accuracy_2)\n",
    "    print(\"Train Accuracy:\", accuracy_1)\n",
    "    print(\"Test Accuracy:\", accuracy_2)\n",
    "\n",
    "# Print the average MCC scores\n",
    "print(\"Train MCC:\", np.mean(train_mcc_scores))\n",
    "print(\"Test MCC:\", np.mean(test_mcc_scores))\n",
    "print(\"Train Accuracy_mean:\", np.mean(accuracy_1))\n",
    "print(\"Test Accuracy_mean:\", np.mean(accuracy_2))\n",
    "\n",
    "print(\"Average Train Accuracy:\", np.mean(train_accuracy_scores))\n",
    "print(\"Average Test Accuracy:\", np.mean(test_accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03ae18db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9598597282234329\n",
      "Test Accuracy: 0.8730369387303694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Train Accuracy:\", np.mean(accuracy_1))\n",
    "print(\"Test Accuracy:\",np.mean(accuracy_2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
